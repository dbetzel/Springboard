{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URTi6EzSsVkL"
   },
   "source": [
    "# Word-Level Text Generation with GPT-2\n",
    "\n",
    "GPT-2 is a large transformer-based language model trained on a dataset of 8 milion web pages. It's objective is to predict the next word, based on all the previous words within some text.\n",
    "\n",
    "We'll use Hugging Face Tranformers library which provides over 32+ pretrained models for NLG and NLU (ready to use in PyTorch abd TensorFlow 2.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RkmGGUDrtc3Z",
    "outputId": "6f911a65-0b15-4e2d-f9e1-be0a42411084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/nlg_tales_generation'\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "%cd 'drive/MyDrive/Colab Notebooks/nlg_tales_generation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQWThEqKt24W",
    "outputId": "999be557-f71a-466e-840e-c1e8b0ef0015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 8.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 53.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 62.9 MB/s \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 59.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Gtv8aH0FshHu"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    GPT2Tokenizer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    TextDataset,\n",
    "    GPT2LMHeadModel,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B4tMv21atmNj"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/train.txt'\n",
    "test_path = '/content/test.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nluUoX1Gvcu"
   },
   "source": [
    "## Text tokenization\n",
    "\n",
    "Tokenizer splits text into tokens (words or subwords, punctuation etc.) and then converts them into numbers (ids) to be able to feed them to the model.\n",
    "\n",
    "When using a pretrained transformers model, the associated pretrained tokenizer should be used in order to preserve the same way of transforming words into tokens (as during pretraining).\n",
    "We can use either the tokenizer class associated to the model (eg. GPT2Tokenizer) or the AutoTokenizer class.\n",
    "\n",
    "Size of text corpus used to train transformers results in a big vocabulary size that requires an increased memory and time complexity. To avoid it, transformers models use subword tokenization (a hybrid between word-level and character level tokenization).\n",
    "\n",
    "GPT-2 uses Byte-Pair Encoding (BPE) with space tokenization as pretokenization. Its vocabulary size is 50,257 with 256 bytes base tokens.\n",
    "\n",
    "Learn more:\n",
    "* [GPT2Tokenizer Docs](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2tokenizer)\n",
    "* [Preprocessing data](https://huggingface.co/transformers/preprocessing.html)\n",
    "* [Summary of tokenizers](https://huggingface.co/transformers/tokenizer_summary.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "64d82d3ea8344cf68cc56efcbc6c6591",
      "2ba8f37926d443f68053ad0b685efe13",
      "808716d416b64f76b5b892128a7cd044",
      "a1e3d8d20970454b95278b30ee54fd8f",
      "2fb6ea3059004219936fbea734aaebe7",
      "f76b7002d2294da3a8515a026f1d6029",
      "c7f5b0c5403a402990f6c26126cedb50",
      "1ee59fb61a47456c9d3d80496221b823",
      "f4a970b5d928446dbced11df9dc0d796",
      "e1bfa670d90c42bbb6df453592aa0b8f",
      "68e9e4ae236545809f8289dd43c3fda3",
      "e48bd59771734d25ae9c2b07ef228da9",
      "70d1adca1a82433d8e9c0cec7aa64c01",
      "ce8e76b63c634981abf4c4b934ea6e39",
      "5f209e685feb4001af6c72e024db6c82",
      "e540e9eef874411080dfbd201501dd49",
      "7c3c0490dd304d1aa2655f8a931ac972",
      "7d699245ed744e5682a3a8f63b0968e3",
      "196bcb8cd1344b9a8e603e3093428f91",
      "b60aa8bda08d4f6693670a2e31f88d32",
      "de6dbe3994e0468cb166358d81351f9f",
      "c45bfb16f59a4ac4921036a01f54b007",
      "0f43cbc0271a48e992743196e65e8764",
      "1827c736fccf41efa405d12145ecda4c",
      "ecbf85064b50456c9304d8779f08b6a6",
      "0b70932faff4436aba8e8246dd02903e",
      "9b69dcc71c3b44238ed4f4a2e0d3d4ac",
      "7b1ec21703ea4d9e94eec6db2e68735a",
      "6d744894198b4d91b2438b20311092de",
      "bb4ed5ae2d8a4023914d5a256b212ab0",
      "742b7093b8d946caa7197946999420d4",
      "00ba7bd7f1244197840864322cc610be",
      "a743f743723f416e8ade1ee4d764e101",
      "79cd40a5671545a7a7f9de856f439fba",
      "27754e01ca5a43b0a8fafcae7b870f19",
      "4b5c18b765b7460fb85602f931de6fb8",
      "a5b3418fd31d4cf18f97655f6ba2bd1f",
      "a6bad6cb11c94175af80c67762b56aef",
      "b3a00d73e44c4546aca9a234c35f8bb2",
      "600e08d9ab17432198dca4d63023562f",
      "025667ca821245f889a9971dd1be355a",
      "a9c730088f0041f29f1ac609782c42df",
      "1bc76bd9ccca4a7e8743939d7fe5da7d",
      "79689232a22b4351a4e5e40475db3b97"
     ]
    },
    "id": "_NhdiC44t1Qu",
    "outputId": "d5a1ebf7-ee54-440e-beb9-41956539e835"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d82d3ea8344cf68cc56efcbc6c6591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48bd59771734d25ae9c2b07ef228da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f43cbc0271a48e992743196e65e8764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cd40a5671545a7a7f9de856f439fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_8HFSmbLqlZ"
   },
   "source": [
    "When feeding the sentence to the tokenizer, it returns a dictionary with a list of input_ids (indeces corresponding to each token). There is also an argument called attention mask which indicates to the model which tokens should be attended to and which not (to skip padded tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dw7JSpl_IfR2",
    "outputId": "da664308-ee86-4ba4-8870-52585da00ec7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 50257, max squence length: 1024\n",
      "tokenize sequence \"Once upon a time in a little village\": {'input_ids': [7454, 2402, 257, 640, 287, 257, 1310, 7404], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print('vocabulary size: %d, max squence length: %d' % (tokenizer.vocab_size, tokenizer.model_max_length))\n",
    "print('tokenize sequence \"Once upon a time in a little village\":', tokenizer('Once upon a time in a little village'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fJUF4aQNcDp"
   },
   "source": [
    "A DataCollator is a function used to form a batch from train and test dataset. DataCollatorForLanguageModelling dynamically padds inputs to the maximum length of a batch if they are not all of the same length. GPT-2 uses causual language modeling (not masked language modeling) - its goal is to predict the token following a sequence of tokens (so the model only attends to the left context). That is why, mlm should be set to False.\n",
    "\n",
    "At this point, we don't fit tokenizer and data collator to the data - it will be loaded as a part of Trainer object later.\n",
    "\n",
    "Learn more:\n",
    "* [Casual Language Modelling](https://huggingface.co/transformers/task_summary.html#causal-language-modeling)\n",
    "* [Data Collator](https://github.com/huggingface/transformers/blob/master/src/transformers/data/data_collator.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X6kx9z-4Na2n"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMdGGdo_yIWP"
   },
   "source": [
    "## Load dataset\n",
    "\n",
    "In order to use text data in the model, we should load it as a Dataset object (from PyTorch). The Dataset object needs to contain the definition of \\__init\\__, \\__getitem\\__ and \\__len\\__. [This tutorial](https://huggingface.co/transformers/custom_datasets.html) provides examples of custom dataset objects.\n",
    "\n",
    "We'll use HuggingFace implementation of TextDataset. It splits the text into consecutive blocks of certain length, e.g., it will cut the text every 1024 tokens.\n",
    "\n",
    "Learn more:\n",
    "* [Hugging Face implementation](https://github.com/huggingface/transformers/blob/master/src/transformers/data/datasets/language_modeling.py)\n",
    "* [Stack Overflow explanation](https://stackoverflow.com/questions/60001698/how-exactly-should-the-input-file-be-formatted-for-the-language-model-finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2unR0INKyHjZ",
    "outputId": "1283a41c-0fc9-4f3a-a33e-67b527475da6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/data/datasets/language_modeling.py:58: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_mlm.py\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=train_path,\n",
    "    block_size=128)\n",
    "     \n",
    "test_dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=test_path,\n",
    "    block_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_1a0dke6MACf",
    "outputId": "9d99b07a-c33b-433f-9ae0-83fc6130157e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "till they reached a great stone wall, many, many feet high.\n",
      "\n",
      "'Now, prince,' said the magpie, 'the three bulrushes are behind that\n",
      "wall.'\n",
      "\n",
      "The prince wasted no time. He set his horse at the wall and leaped over\n",
      "it. Then he looked about for the three bulrushes, pulled them up and\n",
      "set off with them on his way home. As he rode along one of the bulrushes\n",
      "happened to knock against something. It split open and, only think! out\n",
      "sprang a lovely girl, who said: 'My heart's\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_dataset[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcexcKIjW78p"
   },
   "source": [
    "## Fine-tune model\n",
    "\n",
    "Transformers library allows to fine-tune an existing (pretrained) model or train a model from scratch (with a custom configuration).\n",
    "\n",
    "We'll use GPT-2 pretrained model by loading it with .from_pretrained() method. Just like with the tokenizer, the model can be loaded with the class associated to the model (eg. GPT2LMHeadModel) or with the AutoModel class.\n",
    "\n",
    "GPT2LMHeadModel is the GPT-2 model dedicated to language modeling tasks.\n",
    "\n",
    "Learn more:\n",
    "* [GPT2LMHeadModel](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2lmheadmodel)\n",
    "* [Fine-tuning a model](https://huggingface.co/transformers/training.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "1ceee67f0db64e379f9cf559edb8ca84",
      "3db1119d9dbf4ca99fda1ccf2342da8e",
      "041e203f69a4405c902629211575a2c2",
      "6b932db9d9f84ce4903e56bd1bf587c2",
      "58e42ea747fc478e99747cab881e8cc0",
      "dd88d5cc5b714376b94b662d39ab1218",
      "66a9c2094915458284ba52d1869848eb",
      "1b7852ebfcf8422ea76004f5cb4a9473",
      "eef956c8b52f48518ab777312aaf282b",
      "9a52b8b09c3e4bd0b9c34460e547a95f",
      "3b0b61a9f9e94603a486399cbdb0ffa6"
     ]
    },
    "id": "2F8pQODVWneU",
    "outputId": "3c1a37ea-a04d-4e64-879e-9872d9c77e4e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceee67f0db64e379f9cf559edb8ca84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLfaPpdM38nR"
   },
   "source": [
    "The Trainer class provides an interface for feature-complete training - it enables training, fine-tuning, and evaluating any transformers model. It takes as input: the model, training arguments, datasets, data collator, tokenizer etc.\n",
    "\n",
    "The Training Arguments is a subset of arguments that relate to the training loop - we can set up eg: batch size, learning rate, number of epochs.\n",
    "\n",
    "Learn more:\n",
    "* [Trainer](https://huggingface.co/transformers/main_classes/trainer.html#transformers.Trainer)\n",
    "* [Training Arguments](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oAi2FPg_37-R"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = 'data/out', # the output directory for the model predictions and checkpoints\n",
    "    overwrite_output_dir = True, # overwrite the content of the output directory\n",
    "    per_device_train_batch_size = 32, # the batch size for training\n",
    "    per_device_eval_batch_size = 32, # the batch size for evaluation\n",
    "    learning_rate = 5e-5, # defaults to 5e-5\n",
    "    num_train_epochs = 3, # total number of training epochs to perform\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "AEHeEOiq-vzl",
    "outputId": "957c4a89-85cf-4687-b32a-74d28e6623ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 25362\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2379\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2379' max='2379' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2379/2379 45:10, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.391000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.110500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to data/out/checkpoint-500\n",
      "Configuration saved in data/out/checkpoint-500/config.json\n",
      "Model weights saved in data/out/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to data/out/checkpoint-1000\n",
      "Configuration saved in data/out/checkpoint-1000/config.json\n",
      "Model weights saved in data/out/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to data/out/checkpoint-1500\n",
      "Configuration saved in data/out/checkpoint-1500/config.json\n",
      "Model weights saved in data/out/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to data/out/checkpoint-2000\n",
      "Configuration saved in data/out/checkpoint-2000/config.json\n",
      "Model weights saved in data/out/checkpoint-2000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2379, training_loss=3.2050266081468055, metrics={'train_runtime': 2712.0475, 'train_samples_per_second': 28.055, 'train_steps_per_second': 0.877, 'total_flos': 4970166386688000.0, 'train_loss': 3.2050266081468055, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTyLyJv7-v14",
    "outputId": "5e1cc465-ee21-4ef1-c7ff-476f15b75b9a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to data/out\n",
      "Configuration saved in data/out/config.json\n",
      "Model weights saved in data/out/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wx-faJxg4fFY"
   },
   "source": [
    "## Text generation\n",
    "\n",
    "In order to use a model for inference, we should use a pipeline. The pipeline object is a wrapper around all the other available pipelines, eg using pipeline with task parameter set to \"text-generation\" references to the task-specific pipeline: TextGenerationPipeline. TextGenerationPipeline uses any ModelWithLMHead to predict the next words following a specified prefix.\n",
    "\n",
    "The pipeline object (defined as generator in this case) takes arguments which are defined in PretrainedConfig (section: _Parameters for sequence generation_).\n",
    "\n",
    "Learn more:\n",
    "* [Pipeline](https://huggingface.co/transformers/main_classes/pipelines.html)\n",
    "* [TextGenerationPipeline](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.TextGenerationPipeline)\n",
    "* [PretrainedConfig](https://huggingface.co/transformers/main_classes/configuration.html#transformers.PretrainedConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmcIDA7p-v39",
    "outputId": "dcd92b33-1193-420a-f6c8-aff9334f57d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file data/out/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file data/out/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file data/out/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at data/out.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', tokenizer='gpt2', model='data/out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1NHFeo0w1Vi",
    "outputId": "4a6782f6-16f4-476d-9745-b3660a2afbb3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time some\n",
      "young and wicked man had been killed by the wolves that fed on the wood. When\n",
      "this happened his brother was taken to a place where he had lived\n",
      "to-night, and the mother and the child went out in search of food. One of\n",
      "these days he took a wolf and, coming to her, had him tied to a tree\n",
      "and carried away. When he had gone out and taken the wolf, he told her\n",
      "his story. After that another wolf had been killed, this time by the\n",
      "whale who had hunted it. Thus one night the brothers had their supper\n",
      "and they set out together. The night before they could find\n",
      "some berries they brought back a wolf, who carried a bundle of wood. So the\n",
      "brother set out to hunt the wolf and brought him back the bundle. Soon\n",
      "after that he came to a forest where another wolf had killed his brother,\n",
      "also a bundle, and the youngest became the youngest. They set out together\n",
      "to hunt together in the forest together, but the youngest, still sleeping\n",
      "in the bedspread of the bear, knocked at the door and said: 'I have brought\n",
      "a bundle of wood with you, and will lay you before her.'\n",
      "\n",
      "'Now you must be very thirsty,' replied the bear, 'and go in to ask me the water.' So\n",
      "the brother went in, and when he saw the bear he lifted a bundle from\n",
      "a tree and drank, and there was a long sleep.\n",
      "\n",
      "So he went in and laid his face in it, and saw that one of the bears was alive, and he\n",
      "told the mother how hard he had worked all day. Then he lifted the bear and sat on\n",
      "her head, and the youngest ran to see what had happened. The youngest answered that a great\n",
      "monster lay at the foot of the tree, and that was the wolf whom she had killed. If the\n",
      "monster had eaten her there and done evil to her in all its ways there\n",
      "would have been nothing to eat her at all. So he gave the bear a few sticks of wood and took the\n",
      "other bear in his arms and carried away the wolf. Once more the young man came and told his tale,\n",
      "and then the bear gave him her back her head, for she had not done so in twelve days, for\n",
      "when she came back again the maiden had thought to herself:\n",
      "\n",
      "'Let me see what mischief thou broughtest me, and in what land thou hidest me.' When she saw the prince she\n",
      "opened her eyes and saw both had been born in that castle and both had fallen in love\n",
      "together.\n",
      "\n",
      "But as she slept she saw her husband sitting on his bed, and at the same time saw her brother and daughter\n",
      "fall in love and beheld him awake in the kitchen, and he came down to her, saying:\n",
      "\n",
      "'You have brought misfortune on this poor mother, for her husband is asleep, and she\n",
      "is the son of a witch,' and she took out her knife and cut him, saying: for the\n",
      "wizard and the woman were in great need of a daughter. The elder brother\n",
      "knew that the boy who was there was dead, and asked if he would part with her\n",
      "for a dowry she had brought him for this reason; 'but the\n",
      "other sister must see him and help him; she can tell him also how\n",
      "much she can bear.'\n",
      "\n",
      "Then the witch brought at once to the maiden and bade her kill him.\n",
      "Then she laid hold of the youngest brother and bared her hand and took away all of\n",
      "the wood from her, and in it was her daughter; but her father had\n",
      "no sons, for he had no wife to depend upon. And he made\n",
      "a covenant with the child that the woman should marry the\n",
      "son\n",
      "of the witch. The little girl had her husband, who was very kind, and\n",
      "brought her back to her. So he let her go once more to the\n",
      "king and there lived the king's daughter, who called herself\n",
      "Princess\n",
      "Jane.\n",
      "\n",
      "'Now,' she continued to-day, 'when thou wilt return we will give thee my daughter\n",
      "Princess Jane\n",
      "\n",
      "Jane. There will be none to-night, even thou wilt never see the maiden again, for\n",
      "the child wisheth about in that castle and, with me, as much knowledge thereof as\n",
      "thou\n",
      "stere\n",
      "hither.' And the king said:\n",
      "\n",
      "'Let it be to her,' and she returned to her husband, and when she had done with\n",
      "him the husband gave her a daughter.\n",
      "\n",
      "'Now,' she continued, 'she has come to be a maiden, and will be called\n",
      "Princess Jane, and shall be given to thy son as long\n"
     ]
    }
   ],
   "source": [
    "print(generator('Once upon a time', max_length=1000)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG_Aqwp9F9OL"
   },
   "source": [
    "## Text generation with different decoding methods\n",
    "\n",
    "Better decoding methods play an important role in improving performance of language models. Huggingface transformers allow to easily implement such decoding methods as: Greedy search, Beam search, Top-K sampling and Top-p sampling.\n",
    "\n",
    "Learn more:\n",
    "* [Different decoding methods for language generation](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb)\n",
    "\n",
    "_Greedy search_ simply selects the word with the highest probability as the next word (the default text generation mode). This method can possibly result in the model repeating itself and missing high probability words hidden behind low probability words.\n",
    "\n",
    "_Beam search_ evaluates num_beams consecutive words and selects the ones with the highest overall probability. It reduces the risk of missing hidden high probability words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y97LkL-LaAfI",
    "outputId": "0edbdbf0-9d84-4b19-e3dc-99b5b0847d7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a king who had a son, and he\n",
      "had a daughter, and she was very beautiful, and he had two sons, and\n",
      "they were very good-looking, and they were very good-looking, too, and they were\n",
      "very good-looking, too, and they were very good-looking, too, and they were\n",
      "very good-looking, too, and they were very good-looking, too, and they were\n",
      "very good-looking, too, and they were very good-looking, too, and they were\n",
      "very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they\n",
      "were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were\n",
      "very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were\n",
      "very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they were very good-looking, too, and they were very good-looking,\n",
      "too, and they were very good-looking, too, and they\n"
     ]
    }
   ],
   "source": [
    "text_beam = generator('Once upon a time',\n",
    "                      max_length=500,\n",
    "                      num_beams=5)\n",
    "print(text_beam[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND7TnMghJUOG"
   },
   "source": [
    "On the other hand, text generated by humans doen not follow a distribution of high probability next words, that's why it's worth introducing some randomness while decoding model output.\n",
    "\n",
    "We can introduce _random sampling_ of next word, that is, picking the next word acording to its conditional probability distribution. What's more, by adding _softmax temperature_ we can make the distribution sharper (increasing the likelihood of high probability words and the opposite for low probability words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOSvfmVwfUE5",
    "outputId": "91aec4a0-ae3b-4eee-9a82-0738fa8988e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time this place was called \"the\n",
      "land of the giants.\" The name of it was \"the Hyacinth,\" and the\n",
      "name of its people was \"the fairies.\" The name of their kind was\n",
      "\"the fairies.\" The place was like a great garden, so that\n",
      "the natural light was so slight that even the dead could see it at\n",
      "sight. All the people were asleep and dreaming, but they were\n",
      "quite wise and clever. They had a large stable built in their\n",
      "own land to keep the fairies and the fairies' children.\n",
      "\n",
      "One day the fairies awoke and saw a little girl in bed. She was\n",
      "beautiful, so elegant and so young, but she was not as beautiful as\n",
      "her sisters had been. The fairies said to her, \"Hey, what's that, little\n",
      "girl?\" and she said, \"Well, look, my dear mother, you are a little\n",
      "old lady, but what's the matter?\"\n",
      "\n",
      "\"Oh! a little old lady, just come with me,\" said the fairies. \"Go at once; it is\n",
      "time to go to sleep.\"\n",
      "\n",
      "\"Oh! how glad my mother is!\" said the little girl. \"I will take you home\n",
      "with me.\"\n",
      "\n",
      "\"You're not going to be snow-covered,\" said the fairies. \"You must be on your horse, for\n",
      "you are so large that you can stand there on your head. The wind will be terrible, and\n",
      "I cannot keep you up long.\"\n",
      "\n",
      "\"You must be my own mother,\" said the little girl. \"You must have a carriage ready to take me, and\n",
      "carry me, since I cannot get up on my back.\"\n",
      "\n",
      "The fairies thought that if the little girl could not be with her, she really must be her\n",
      "brother. They were getting tired of the old woman's coarse clothes, and they began\n",
      "to think of a way to keep her safe from the wind.\n",
      "\n",
      "\"I think I shall come through the woods with you,\" said they. \"You may go in; I must have my horses, for\n",
      "I have a big stable for you to keep the fairies.\"\n",
      "\n",
      "So they set out on their journey, and the fairies came to a great old tree where they\n",
      "saw the fairies. They put their horses on their back, and the fairies called out to them,\n",
      "\"Do you want to stay here too?\"\n",
      "\n",
      "\"I want a stable for you,\" the old woman answered; \"but if you will give me a little sailboat, and\n",
      "carry me away with me, you will get your eggs.\"\n",
      "\n",
      "\"No, no,\" said the fairies, \"I want a boat, too, for I will not shed my tears.\"\n",
      "\n",
      "\"I will give you a boat to carry you away, but I will not shed my tears,\" said the\n",
      "sailboat. \"The wind is dreadful, and it breaks the young man's arms, and if I\n",
      "give you a little sailboat, and carry you away with you, I will not shed\n",
      "my tears.\"\n",
      "\n",
      "Then she said, \"I will give you a boat to carry you away, but I will not shed\n",
      "my tears.\" And when the fairies were all alone in the trees, they\n",
      "went into the stable, and the fairies went in and told the old woman\n",
      "that the little girl had a small hut, and it was safe on her back,\n",
      "and that if they did not go to the stable, the fairies would kill\n",
      "her. The fairies were very frightened at the idea of the little\n",
      "girl, and said to her, \"Go away, and we will cut her to\n",
      "pieces.\"\n",
      "\n",
      "But the old woman did not hear her, and went into the hut and cut the little\n",
      "girl to pieces, and put her in a big wooden box, and took her to\n",
      "the barn, where the fairies brought her up from the\n",
      "stable, and put her in a big wooden box, and put her in a\n",
      "bridemaid's box, and laid the little girl in the box, and laid the\n",
      "little\n",
      "girl in the bridemaid's box, and laid the little little girl in the\n",
      "bridemaid's box, and laid the little maiden in the bridemaid's box; and\n",
      "the fairies got rid of the old woman, and put the little girl\n",
      "into a big wooden box, and laid the little girl in the bridemaid's\n",
      "box, and laid the little girl in the bridemaid's box, and laid the little\n",
      "girl in the bridemaid's box, and laid the little maiden in the\n",
      "bridemaid's box, and lay the little maiden in the bridemaid's box\n"
     ]
    }
   ],
   "source": [
    "text_random_sampling = generator('Once upon a time',\n",
    "                                 max_length=1000,\n",
    "                                 top_k=0,\n",
    "                                 do_sample=True,\n",
    "                                 temperature=0.7)\n",
    "print(text_random_sampling[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCsqoxMjKdBM"
   },
   "source": [
    "_Tok k-sampling_ method limits the sampling pool to k words with the highest probability thus it allows us to eliminate the most unlikely words.\n",
    "\n",
    "On the other hand, _Top-p sampling_ chooses from the smallest possible set of words whose cumulative probability exceeds the probability p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rGhv9MtsieXC",
    "outputId": "a533ff37-adf0-48f2-fe66-07bc60066927"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time they told such a story to the boy,\n",
      "that he felt very much moved.  They gave him a basket and shoes, and said\n",
      "they would never refuse him a basket with the same name on them, for he would\n",
      "never refuse them the first time!  The second time, though he was very\n",
      "young, the boy gave more and sweeter compliments on his new basket.\n",
      "\n",
      "'What did you want, my little boy?' he asked.  \"'It was you who had invented\n",
      "the golden-pigeon cap, and I am your friend-boy-to-the-fairy-apple,\n",
      "that we have all been waiting for, and it was me who first told you\n",
      "it.'  Then they carried it away to the prince's palace, and put it on his\n",
      "back, and the prince never looked at it till they had all lost all\n",
      "their money.  'Well,' said the young man, 'when I come back I will show you some\n",
      "things I could carry with me to fetch some apples.'\n",
      "\n",
      "The boy's father gave each of the boy and the mother a basket, and said he\n",
      "would certainly find them useful.\n",
      "\n",
      "'What have you to do with the apples?  To-morrow I'll make them the new\n",
      "golden-pigeon cap, which you can have at home any time of the day,'\n",
      "and he led them home again.\n",
      "\n",
      "Now as the two little boys came home he was very fond of apples, so he did not go\n",
      "away at all the next morning without them.  He wandered about with each one and\n",
      "asked the prince what he liked best, and whether he knew at all where to get them.\n",
      "\n",
      "'What's the use of being the little boy who has no basket?' he said, and the prince answered\n",
      "that he would like a little apple with all his money of every kind.\n",
      "\n",
      "'You have to think of something,' laughed the little boy, and he went home to make good his new\n",
      "chamber.\n",
      "\n",
      "Now the prince had hardly learnt some magic when, as he was going into his father's room, he saw\n",
      "it was a nice basket under one of the lamps.  It was such a nice basket to have; but as\n",
      "he looked it he saw it was not very old, that everything fell into place; and it was only a little\n",
      "couch from the bed he had slept in, at the bottom of which he stood up, and lay down on the sofa\n",
      "while the king, who was lying on the sofa, lay still.  When he was dressed for bed, the basket fell into his\n",
      "pocket, and he went off and began to read the book that the king had given him.\n",
      "\n",
      "'What sort of apples can I have?' he asked.  Suddenly the castle door opened, and a beautiful\n",
      "bird flew on to him.  And when he looked at the bird he saw that it was a very good\n",
      "bird, and the prince gave her permission to fly, and went along with her.  A little way\n",
      "away she flew up the staircase to the palace, and down the little\n",
      "tower she sat beneath the fire, and her eyes sparkled for a moment.  Her wings\n",
      "were so big that she could hardly fly, but that little bird\n",
      "was the more beautiful of the two, for they were both so small\n",
      "that she could scarcely be found in its place.  When the prince saw the\n",
      "bird again it cried: 'O king, come on! what have you done to me?\n",
      "I cannot see anything.'\n",
      "\n",
      "After a short rest the boy sat down at the fire, and the king made\n",
      "a cup of wine and said that perhaps he might see the bird\n",
      "more.  'Oh, what a lovely bird!' says the bird: 'I could never\n",
      "be sure of that from my dear little bird, that was not\n",
      "the golden plumage that\n",
      "it had come from; but I can at least count how many times I've loved what\n",
      "thou\n",
      "wooed.'\n",
      "\n",
      "'Oh, my dear little bird!' says the prince, and he took off a basket and a\n",
      "bundle and sat down and began to read the book that the\n",
      "king had given him.  'What sort of apples can I have?'\n",
      "\n",
      "'Oh, that one!' says the bird.  'It was your little bird!'\n",
      "\n",
      "'Well, I'm glad he had never seen me, and I might have been able to tell him\n",
      "my whole story,' says the king.  'But there is one thing\n",
      "I want now, after all, that would make him happy: if you let him out\n",
      "of his palace, he can never see us again; and if the prince lets\n",
      "him out of his\n"
     ]
    }
   ],
   "source": [
    "text_k_sampling = generator('Once upon a time',\n",
    "                            max_length=1000,\n",
    "                            top_k=40,\n",
    "                            do_sample=True)\n",
    "print(text_k_sampling[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aU4IEMP1ieZe",
    "outputId": "172f3e6d-54c0-484f-80f8-571badb71a5c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there lived an old man who came to seek\n",
      "his fortune in beauty and wealth.  He gave his old mistress the\n",
      "wonderful portrait that now stood in his stead.\n",
      "\n",
      "He therefore entrusted the request which she now gave him.  He made a\n",
      "charity of money to whoever could give it to him, and placed\n",
      "her on his journeymen, and thus far he never made any mistake.\n",
      "\n",
      "\"Wherefore, my child?\" said the old man.\n",
      "\n",
      "\"Well, it is all right, my child, that you have settled in home for\n",
      "all eternity.  I have, by the hand of my beloved, replaced the old\n",
      "olde house with a new one.  I want to give you my first diamond and\n",
      "silver.  For I am well satisfied with what I have obtained from you.  You\n",
      "must now purchase both of these things.\"\n",
      "\n",
      "\"What is that then?\" cried the old woman, turning to the youth.  \"What are\n",
      "you saying?\"\n",
      "\n",
      "\"I am saying that the lady who raised me here, when I grew up, suffered a great\n",
      "distress from the well-ordered world, which she bore me to do; but from time to time,\n",
      "she will forget me; for she believed, without knowing, that if she saw me,\n",
      "she should feel herself treated justly.  Her love for me always remains\n",
      "quite unknown to me; nevertheless, she is well contented, and not a single day\n",
      "makes me depart from the world.  Therefore, the best that may be done to enable\n",
      "it to be done is to amuse me with the inscription on the glass, 'I am\n",
      "sorry and helpless.'\n",
      "\n",
      "\"I will make a present of these wonderful treasures to her,\" continued the young man.\n",
      "\n",
      "\"Dear me,\" said he, \"are the golden pomegranates, which she herself baked.  But do you\n",
      "think I should get rich yourself if I told you she must do you honour.\n",
      "How glad you are to hear what has become of the old you-and-your-slave,\n",
      "that the dress that she brought you this evening is not what it was but a gold, and you cannot\n",
      "tell me what the rank of your royal companion has become.  Take him here again, and I will give you\n",
      "a hundred pieces of gold.  Would you like the suit?\"\n",
      "\n",
      "\"Oh, sir,\" said the old man, \"it is not worth it.  I am now about to keep him longer, and I want\n",
      "to ask you in the way that you like.  What is your house?\"\n",
      "\n",
      "\"Here,\" answered the youth, \"is a great palace, and far outside it is the palace of my great master,\n",
      "who have ever saved me from the things that I have done as a pet, and in a few days they\n",
      "will be under my power.  Come, bring me and my master, who takes my suit\n",
      "to-night, and I will guide him from the place to the palace.\n",
      "\n",
      "If you do not persuade him, you can soon seize him and take him to the room\n",
      "of the lady who raised him, and take him to her presence.  I will then\n",
      "conduct the child to the queen.\"\n",
      "\n",
      "The youth and his master then rested, and set about their preparations.\n",
      "\n",
      "They set forth at the palace gate and entered a palace that was a little\n",
      "longer than the ones the princes had called themselves\n",
      "above, for they had been overjoyed at hearing\n",
      "the news of their daughter's new arrival.  They mounted a horse\n",
      "to be followed by their men, and the young man and the\n",
      "shepherd, also, walked to the palace.\n",
      "\n",
      "\"I am anxious to have my father's daughter,\" said the old\n",
      "shepherd, and he gave orders to\n",
      "set off in the direction they wanted, and to arrive there when they\n",
      "had.\n",
      "\n",
      "He followed them for a long while until he came to a cave, where the stone\n",
      "should\n",
      "lead him to.  At the top of the rock he peered up, and he beheld the\n",
      "little gate, to which he had just been led, and the door had\n",
      "been bent, and he was led into an immense hall\n",
      "on the left, without windows to prevent him from walking on.\n",
      "\n",
      "There the young man saw in front of him two knights with long\n",
      "legs who were riding by, and bending down to kiss him.\n",
      "\n",
      "\"Are you my son?\" said the young man, \"and will you accept the\n",
      "duties of your master when\n",
      "he comes on your way?\"\n",
      "\n",
      "\"Yes, my child,\" said the old woman.  \"I will accompany you wherever you\n",
      "may, and I will carry you home\n"
     ]
    }
   ],
   "source": [
    "text_p_sampling = generator('Once upon a time',\n",
    "                            max_length=1000,\n",
    "                            top_k=0,\n",
    "                            top_p=0.92,\n",
    "                            do_sample=True)\n",
    "print(text_p_sampling[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "gpt_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ba7bd7f1244197840864322cc610be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "025667ca821245f889a9971dd1be355a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "041e203f69a4405c902629211575a2c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_66a9c2094915458284ba52d1869848eb",
      "placeholder": "​",
      "style": "IPY_MODEL_dd88d5cc5b714376b94b662d39ab1218",
      "value": "Downloading: 100%"
     }
    },
    "0b70932faff4436aba8e8246dd02903e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_742b7093b8d946caa7197946999420d4",
      "max": 1355256,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb4ed5ae2d8a4023914d5a256b212ab0",
      "value": 1355256
     }
    },
    "0f43cbc0271a48e992743196e65e8764": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ecbf85064b50456c9304d8779f08b6a6",
       "IPY_MODEL_0b70932faff4436aba8e8246dd02903e",
       "IPY_MODEL_9b69dcc71c3b44238ed4f4a2e0d3d4ac"
      ],
      "layout": "IPY_MODEL_1827c736fccf41efa405d12145ecda4c"
     }
    },
    "1827c736fccf41efa405d12145ecda4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "196bcb8cd1344b9a8e603e3093428f91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b7852ebfcf8422ea76004f5cb4a9473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1bc76bd9ccca4a7e8743939d7fe5da7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1ceee67f0db64e379f9cf559edb8ca84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_041e203f69a4405c902629211575a2c2",
       "IPY_MODEL_6b932db9d9f84ce4903e56bd1bf587c2",
       "IPY_MODEL_58e42ea747fc478e99747cab881e8cc0"
      ],
      "layout": "IPY_MODEL_3db1119d9dbf4ca99fda1ccf2342da8e"
     }
    },
    "1ee59fb61a47456c9d3d80496221b823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27754e01ca5a43b0a8fafcae7b870f19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ba8f37926d443f68053ad0b685efe13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fb6ea3059004219936fbea734aaebe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68e9e4ae236545809f8289dd43c3fda3",
      "placeholder": "​",
      "style": "IPY_MODEL_e1bfa670d90c42bbb6df453592aa0b8f",
      "value": " 1.04M/1.04M [00:00&lt;00:00, 1.46MB/s]"
     }
    },
    "3b0b61a9f9e94603a486399cbdb0ffa6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3db1119d9dbf4ca99fda1ccf2342da8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b5c18b765b7460fb85602f931de6fb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_600e08d9ab17432198dca4d63023562f",
      "placeholder": "​",
      "style": "IPY_MODEL_b3a00d73e44c4546aca9a234c35f8bb2",
      "value": "Downloading: 100%"
     }
    },
    "58e42ea747fc478e99747cab881e8cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b0b61a9f9e94603a486399cbdb0ffa6",
      "placeholder": "​",
      "style": "IPY_MODEL_9a52b8b09c3e4bd0b9c34460e547a95f",
      "value": " 548M/548M [00:12&lt;00:00, 47.0MB/s]"
     }
    },
    "5f209e685feb4001af6c72e024db6c82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b60aa8bda08d4f6693670a2e31f88d32",
      "max": 456318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_196bcb8cd1344b9a8e603e3093428f91",
      "value": 456318
     }
    },
    "600e08d9ab17432198dca4d63023562f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64d82d3ea8344cf68cc56efcbc6c6591": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_808716d416b64f76b5b892128a7cd044",
       "IPY_MODEL_a1e3d8d20970454b95278b30ee54fd8f",
       "IPY_MODEL_2fb6ea3059004219936fbea734aaebe7"
      ],
      "layout": "IPY_MODEL_2ba8f37926d443f68053ad0b685efe13"
     }
    },
    "66a9c2094915458284ba52d1869848eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e9e4ae236545809f8289dd43c3fda3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b932db9d9f84ce4903e56bd1bf587c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eef956c8b52f48518ab777312aaf282b",
      "max": 548118077,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b7852ebfcf8422ea76004f5cb4a9473",
      "value": 548118077
     }
    },
    "6d744894198b4d91b2438b20311092de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70d1adca1a82433d8e9c0cec7aa64c01": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "742b7093b8d946caa7197946999420d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79689232a22b4351a4e5e40475db3b97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79cd40a5671545a7a7f9de856f439fba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b5c18b765b7460fb85602f931de6fb8",
       "IPY_MODEL_a5b3418fd31d4cf18f97655f6ba2bd1f",
       "IPY_MODEL_a6bad6cb11c94175af80c67762b56aef"
      ],
      "layout": "IPY_MODEL_27754e01ca5a43b0a8fafcae7b870f19"
     }
    },
    "7b1ec21703ea4d9e94eec6db2e68735a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7c3c0490dd304d1aa2655f8a931ac972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d699245ed744e5682a3a8f63b0968e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "808716d416b64f76b5b892128a7cd044": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c7f5b0c5403a402990f6c26126cedb50",
      "placeholder": "​",
      "style": "IPY_MODEL_f76b7002d2294da3a8515a026f1d6029",
      "value": "Downloading: 100%"
     }
    },
    "9a52b8b09c3e4bd0b9c34460e547a95f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b69dcc71c3b44238ed4f4a2e0d3d4ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a743f743723f416e8ade1ee4d764e101",
      "placeholder": "​",
      "style": "IPY_MODEL_00ba7bd7f1244197840864322cc610be",
      "value": " 1.36M/1.36M [00:00&lt;00:00, 4.70MB/s]"
     }
    },
    "a1e3d8d20970454b95278b30ee54fd8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4a970b5d928446dbced11df9dc0d796",
      "max": 1042301,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ee59fb61a47456c9d3d80496221b823",
      "value": 1042301
     }
    },
    "a5b3418fd31d4cf18f97655f6ba2bd1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a9c730088f0041f29f1ac609782c42df",
      "max": 665,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_025667ca821245f889a9971dd1be355a",
      "value": 665
     }
    },
    "a6bad6cb11c94175af80c67762b56aef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79689232a22b4351a4e5e40475db3b97",
      "placeholder": "​",
      "style": "IPY_MODEL_1bc76bd9ccca4a7e8743939d7fe5da7d",
      "value": " 665/665 [00:00&lt;00:00, 21.4kB/s]"
     }
    },
    "a743f743723f416e8ade1ee4d764e101": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a9c730088f0041f29f1ac609782c42df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3a00d73e44c4546aca9a234c35f8bb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b60aa8bda08d4f6693670a2e31f88d32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb4ed5ae2d8a4023914d5a256b212ab0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c45bfb16f59a4ac4921036a01f54b007": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7f5b0c5403a402990f6c26126cedb50": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce8e76b63c634981abf4c4b934ea6e39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d699245ed744e5682a3a8f63b0968e3",
      "placeholder": "​",
      "style": "IPY_MODEL_7c3c0490dd304d1aa2655f8a931ac972",
      "value": "Downloading: 100%"
     }
    },
    "dd88d5cc5b714376b94b662d39ab1218": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de6dbe3994e0468cb166358d81351f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1bfa670d90c42bbb6df453592aa0b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e48bd59771734d25ae9c2b07ef228da9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce8e76b63c634981abf4c4b934ea6e39",
       "IPY_MODEL_5f209e685feb4001af6c72e024db6c82",
       "IPY_MODEL_e540e9eef874411080dfbd201501dd49"
      ],
      "layout": "IPY_MODEL_70d1adca1a82433d8e9c0cec7aa64c01"
     }
    },
    "e540e9eef874411080dfbd201501dd49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c45bfb16f59a4ac4921036a01f54b007",
      "placeholder": "​",
      "style": "IPY_MODEL_de6dbe3994e0468cb166358d81351f9f",
      "value": " 456k/456k [00:00&lt;00:00, 1.06MB/s]"
     }
    },
    "ecbf85064b50456c9304d8779f08b6a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d744894198b4d91b2438b20311092de",
      "placeholder": "​",
      "style": "IPY_MODEL_7b1ec21703ea4d9e94eec6db2e68735a",
      "value": "Downloading: 100%"
     }
    },
    "eef956c8b52f48518ab777312aaf282b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4a970b5d928446dbced11df9dc0d796": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f76b7002d2294da3a8515a026f1d6029": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
